{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NpttnExP8Az",
        "outputId": "5c73ccbb-5e31-4a72-b641-0d8981e54a99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/73.6 kB\u001b[0m \u001b[31m426.4 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m71.7/73.6 kB\u001b[0m \u001b[31m707.9 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m562.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pylcs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install openai pylcs -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPisqftKTsa1",
        "outputId": "f643bbf7-a56c-406f-ab83-3d06898615f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue8u0uipTuMr",
        "outputId": "f93e1ee0-632b-4218-a528-3b88b1fcdf76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Low Resource\n"
          ]
        }
      ],
      "source": [
        "cd drive/MyDrive/Low Resource\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fdkVINIYSprZ"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "import time\n",
        "import pylcs\n",
        "import openai.error\n",
        "import uuid\n",
        "import csv\n",
        "import glob\n",
        "import openai.error\n",
        "import helpers\n",
        "import difflib\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sKURmHloP8A2"
      },
      "outputs": [],
      "source": [
        "openai.api_key = 'INSERT KEY HERE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "96cCujF2Undo"
      },
      "outputs": [],
      "source": [
        "with open('COVID-QA.json','r') as f:\n",
        "  full_data = json.load(f)[\"data\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HYPeXo-Bc6ue"
      },
      "outputs": [],
      "source": [
        "split = 4 * len(full_data) // 5\n",
        "train_data = full_data[:split]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "P77kaICxUnlK"
      },
      "outputs": [],
      "source": [
        "def find_in_context(context, substring):\n",
        "  substring_lower = substring.lower()\n",
        "  context_lower = context.lower()\n",
        "  start = \" \".join(substring_lower.split()[0:3])\n",
        "  end = \" \".join(substring_lower.split()[-3:])\n",
        "  start_idx = context_lower.find(start)\n",
        "  end_idx = context_lower.find(end)\n",
        "\n",
        "  if start_idx != -1 and end_idx != -1:\n",
        "    return context[start_idx:end_idx + len(end)]\n",
        "\n",
        "  return \"\"\n",
        "\n",
        "def process_answers(new_context,curr_answers):\n",
        "  answers = []\n",
        "  for i,answer in enumerate(curr_answers):\n",
        "    if new_context.find(answer) != -1:\n",
        "      answers.append(answer)\n",
        "    elif new_context.find(answer[:-1]) != -1:\n",
        "      answers.append(answer[:-1])\n",
        "    elif new_context.find(answer[0].lower() + answer[1:]) != -1:\n",
        "      answers.append(answer[0].lower() + answer[1:])\n",
        "    elif new_context.find(answer[0].lower() + answer[1:-1]) != -1:\n",
        "      answers.append(answer[0].lower() + answer[1:-1])\n",
        "    elif find_in_context(new_context, answer) != \"\":\n",
        "      answers.append(find_in_context(new_context, answer))\n",
        "    elif find_in_context(new_context, answer[:-1]) != \"\":\n",
        "      answers.append(find_in_context(new_context, answer[:-1]))\n",
        "    else:\n",
        "      answers.append(\"\")\n",
        "\n",
        "  return answers\n",
        "\n",
        "\n",
        "def find_answer_context(context, answer, max_context_length=500, num_sentences_before=3, num_sentences_after=4):\n",
        "    # Strip leading and trailing whitespaces from the answer\n",
        "    answer = answer.strip()\n",
        "\n",
        "    # Find the sentence that contains the answer\n",
        "    if not isinstance(context,str):\n",
        "      return \"\"\n",
        "    context_sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', context)\n",
        "    target_sentence_index = next((i for i, s in enumerate(context_sentences) if answer.lower() in s.lower()), None)\n",
        "\n",
        "    # If no sentence contains the answer, return None\n",
        "    if target_sentence_index is None:\n",
        "        return None\n",
        "\n",
        "    # Determine the start and end indices of the context window\n",
        "    context_start = max(0, target_sentence_index - num_sentences_before)\n",
        "    context_end = min(len(context_sentences), target_sentence_index + num_sentences_after + 1)\n",
        "\n",
        "    # Extract the answer-containing context\n",
        "    answer_context = ' '.join(context_sentences[context_start:context_end])\n",
        "\n",
        "    return answer_context\n",
        "\n",
        "def process_string(input_string):\n",
        "    input_string = input_string.strip(\"\\n\")\n",
        "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s', input_string)\n",
        "\n",
        "    # Calculate the index to extract the bottom 50% of sentences\n",
        "    bottom_half_index = len(sentences) // 2\n",
        "\n",
        "    # Extract the bottom 50% of sentences\n",
        "    bottom_half_sentences = sentences[bottom_half_index:]\n",
        "\n",
        "    # Join the sentences back into a single string without spaces between sentences\n",
        "    result = ' '.join(bottom_half_sentences)\n",
        "\n",
        "    return result\n",
        "\n",
        "def extract_qa_pairs(qa):\n",
        "    # Regular expression patterns to capture questions and answers\n",
        "    question_pattern = r\"(?:Question\\s*:\\s*|Question\\s*\\d+\\s*:\\s*)(.*?)(?=\\n\\s*(?:Question\\s*:\\s*|Question\\s*\\d+\\s*:|Answer\\s*:\\s*|Answer\\s*\\d+\\s*:|$))\"\n",
        "    answer_pattern = r\"(?:Answer\\s*:\\s*|Answer\\s*\\d+\\s*:\\s*)(.*?)(?=\\n\\s*(?:Question\\s*:\\s*|Question\\s*\\d+\\s*:|Answer\\s*:\\s*|Answer\\s*\\d+\\s*:|$))\"\n",
        "\n",
        "    # Extract questions and answers using regular expressions\n",
        "    questions = re.findall(question_pattern, qa, flags=re.DOTALL)\n",
        "    answers = re.findall(answer_pattern, qa, flags=re.DOTALL)\n",
        "\n",
        "    return questions, answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VZjPewcoYFw2"
      },
      "outputs": [],
      "source": [
        "context_multiplier = 3\n",
        "qa_per_context = 20\n",
        "total_articles = 117\n",
        "starting = 0\n",
        "curr_file = \"COVID_AUGMENT_SMALL\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CXW-0iptN38K"
      },
      "outputs": [],
      "source": [
        "with open('COVID_AUGMENT_SMALL.json','r') as f:\n",
        "  dataset = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4jrjU0Ckqk0P"
      },
      "outputs": [],
      "source": [
        "def make_openai_request(prompt: str, model: str, max_tokens=8000):\n",
        "    max_retry_count = 10\n",
        "    retry_count = 1\n",
        "    retry_time_sec = 30\n",
        "\n",
        "    while retry_count < max_retry_count:\n",
        "        try:\n",
        "\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=model, messages=prompt)\n",
        "            answer = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "            # answer = answer.strip().strip('\"')\n",
        "            return answer\n",
        "        except openai.error.APIConnectionError as e:\n",
        "            print(\n",
        "                f\"API connection error: {e}.\\nRetrying in {retry_time_sec}...\")\n",
        "            retry_count += 1\n",
        "            time.sleep(retry_time_sec)\n",
        "        except openai.error.RateLimitError as e:\n",
        "            print(\n",
        "                f\"Rate limit error: {e}.\\nRetrying in {retry_time_sec}...\")\n",
        "            retry_count += 1\n",
        "            time.sleep(retry_time_sec)\n",
        "        except openai.error.Timeout as e:\n",
        "            print(f\"Timeout error: {e}.\\nRetrying in {retry_time_sec}...\")\n",
        "            retry_count += 1\n",
        "            time.sleep(retry_time_sec)\n",
        "        except openai.error.ServiceUnavailableError as e:\n",
        "            print(\n",
        "                f\"ServiceUnavailable error: {e}.\\nRetrying in {retry_time_sec}...\")\n",
        "            retry_count += 1\n",
        "            time.sleep(retry_time_sec)\n",
        "        except OSError as e:\n",
        "          from google.colab import drive\n",
        "          drive.mount('/content/drive')\n",
        "          %cd drive/MyDrive/Low Resource\n",
        "        except openai.error.OpenAIError as e:\n",
        "            print(f\"Unhandled OpenAI error occurred: {e}\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"Unhandled error occurred: {e}\")\n",
        "            break\n",
        "\n",
        "        if retry_count >= max_retry_count:\n",
        "            print(\n",
        "                f\"Retries of {retry_count} exceeded max_retry_count of {max_retry_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BDCO8K-5kxuA"
      },
      "outputs": [],
      "source": [
        "def get_one_shot(dataset):\n",
        "  one_shot = []\n",
        "  for i,data in enumerate(dataset[\"data\"]):\n",
        "    for j,paragraph in enumerate(data[\"paragraphs\"]):\n",
        "      if len(paragraph[\"qas\"]) > 0:\n",
        "        one_shot.append((paragraph[\"context\"],paragraph[\"qas\"][0][\"question\"],paragraph[\"qas\"][0][\"answers\"][0][\"text\"]))\n",
        "  return one_shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7ty0iJh0Nz-S"
      },
      "outputs": [],
      "source": [
        "one_shot = get_one_shot(train_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip11WR6alhM4",
        "outputId": "eddfd243-f11e-45f1-9a6e-9fc3d73ac884"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On document 42/117\n"
          ]
        }
      ],
      "source": [
        "for cnt in range(starting,total_articles):\n",
        "  print(f'On document {cnt + 1}/{total_articles}')\n",
        "  example_context,example_question,example_answer = one_shot[cnt]\n",
        "  short_context = process_string(example_context)\n",
        "\n",
        "  for i in range(context_multiplier - 1):\n",
        "    new_dict = {\"qas\":[],\"context\":\"\"}\n",
        "    context_prompt = [\n",
        "                      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                      {\"role\": \"user\", \"content\": f\"Generate a context that is similar in topic and domain distribution to the given context. Example Context:{short_context}. Context:\"}\n",
        "                      ]\n",
        "    generated_context = make_openai_request(context_prompt, \"gpt-4\")\n",
        "    new_dict[\"context\"] = generated_context\n",
        "    downsized_context = find_answer_context(example_context,example_answer)\n",
        "    example_context = downsized_context if downsized_context != \"\" else example_context\n",
        "\n",
        "\n",
        "    qa_prompt = [\n",
        "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                    {\"role\": \"user\", \"content\": f\"Based only on the given context generate 1 question answer pair. The answer must be only made up of substrings from the context and do not generate any new text for the answer. Context:{example_context}.\"},\n",
        "                    {\"role\": \"assistant\", \"content\": f\"Question: {example_question} Answer: {example_answer}\"},\n",
        "                    {\"role\": \"user\", \"content\": f\"Based only on the given context generate {qa_per_context} question answer pair. The answer must be only made up of substrings from the context and do not generate any new text for the answer. Context:{generated_context}.\"}\n",
        "                ]\n",
        "    qa = make_openai_request(qa_prompt, \"gpt-4\")\n",
        "    if len(qa) > 0 and qa[-1] != \"\\n\":\n",
        "      qa = qa + \"\\n\"\n",
        "    questions,answers = extract_qa_pairs(qa)\n",
        "    answers = process_answers(generated_context,answers)\n",
        "    print(f'    -------->{len([elem for elem in answers if elem != \"\"])} answers kept')\n",
        "\n",
        "\n",
        "    if len(answers) != len(questions):\n",
        "      print(\"      -------> Skipped this passage\")\n",
        "      continue\n",
        "\n",
        "    for j in range(len(questions)):\n",
        "      question = questions[j]\n",
        "      answer = answers[j]\n",
        "      ques_id = str(uuid.uuid4())\n",
        "      ans_start = generated_context.find(answer)\n",
        "\n",
        "      if answer == \"\" or ans_start == -1:\n",
        "        continue\n",
        "\n",
        "      new_dict[\"qas\"].append({\"question\":question, \"id\":ques_id, \"answers\":[{\"text\":answer, \"answer_start\": ans_start}], \"is_impossible\": False})\n",
        "\n",
        "    dataset[\"data\"].append({\"paragraphs\":[new_dict]})\n",
        "    try:\n",
        "      with open(f\"{curr_file}.json\", \"w\") as f:\n",
        "        json.dump(dataset, f)\n",
        "        print(\"    -------> Saved to Json\")\n",
        "    except OSError as e:\n",
        "          from google.colab import drive\n",
        "          drive.mount('/content/drive')\n",
        "          %cd drive/MyDrive/Low Resource\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
